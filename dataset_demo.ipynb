{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noteook includes two demo\n",
    "1. [Download](#download) a track from the JSONL file\n",
    "2. [Parse and extract](#pipeline) tracks in a video using the TrackVerse automated pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='download'></a>\n",
    "## Download tracks from the JSONL file\n",
    "### (1) Read the JSONL file\n",
    "For demo purpose, we only read one track from the 184K-CB300 subset to show how to read the jonsl file and download correspoonding tracks.\n",
    "\n",
    "To download the all tracks, refer to the [download instructions](https://github.com/MMPLab/TrackVerse?tab=readme-ov-file#download-trackverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = './trackverse'\n",
    "\n",
    "JSONL_DIR = \"/home/yibingwei/dataset/object_tracks_db_fixed_detic/tracks_subsets/hdvila_lvis/NoTestVids\"\n",
    "subset = 'LVIS-184K-CB300-T0.0-NoTestVids.jsonl.gzip'\n",
    "    \n",
    "subset_gzip = f'{JSONL_DIR}/{subset}'\n",
    "for line in tqdm.tqdm(gzip.open(subset_gzip, 'rt')):\n",
    "    data = json.loads(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation of the keys\n",
    "\n",
    "- `track_id` - unique track identifier.\n",
    "- `video_size` - [height, width] of the video from which this track was extracted.\n",
    "- `track_ts` - [start_time, end_time] timestamps (seconds) in the original video for the first and last frame in the track.\n",
    "- `top10_lbl` - Class IDs of the top-10 predicted classes for the track, based on class logit score.\n",
    "- `top10_desc` - Names of the top-10 predicted classes for the track, based on class logit score.\n",
    "- `top10_cls` - [[top-10 logits mean], [top-10 logits std]] A list of the mean values of the classification logits for the top 10 classes, and a list of the standard deviations for these logits.\n",
    "- `top10_wcls` - [[top-10 weighted logits mean], [top-10 weighted logits std]] A list of the mean scores for each of the top 10 weighted scores (class logits weighted by the objectness score), and a list of the standard deviations of these scores.\n",
    "- `frame_ts` - timestamps (seconds) in the original video for each frame in the track\n",
    "- `frame_bboxes` - list of bounding box coordinates [top_left_x, top_left_y, bottom_right_x, bottom_right_y] of the object for each frame in the track.\n",
    "- `yid` - YouTube ID for the video from which this track was extracted\n",
    "- `mp4_filename` - Filename of the track produced by running the track extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_id',\n",
       " 'video_size',\n",
       " 'track_ts',\n",
       " 'top10_lbl',\n",
       " 'top10_desc',\n",
       " 'top10_cls',\n",
       " 'top10_wcls',\n",
       " 'frame_ts',\n",
       " 'frame_bboxes',\n",
       " 'yid',\n",
       " 'mp4_filename']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Download the orignial video from Youtube \n",
    "to DATASET_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo] Already downloaded.\n",
      "[0][1l4wfwq2TLo] Already split into segments.\n"
     ]
    }
   ],
   "source": [
    "from download_videos import VideoDownloader, parse_arguments as parse_dl_args\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "args = parse_dl_args()\n",
    "args.base_dir = DATASET_PATH\n",
    "args.yid_index_fn = ''\n",
    "    \n",
    "downloader = VideoDownloader(args)\n",
    "downloader.process_video(youtube_id=data['yid'], job_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Extract the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo] Start track extraction\n",
      "[0][1l4wfwq2TLo] Track extraction done.\n"
     ]
    }
   ],
   "source": [
    "from extract_tracks import ObjectTrackExtractor, Track\n",
    "import numpy as np\n",
    "extractor = ObjectTrackExtractor(base_dir=DATASET_PATH)\n",
    "\n",
    "tracks = [Track(\n",
    "            data['yid'],\n",
    "            ts=np.array(data['frame_ts']).astype(float),\n",
    "            boxes=np.array(data['frame_bboxes']).astype(float),\n",
    "            meta=data\n",
    "            )]\n",
    "extractor.extract_tracks_from_video(vid=data['yid'], tracks=tracks, job_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./trackverse/tracks_mp4/TrackVerseLVIS/1l/1l4wfwq2TLo-coat-0b20cf63ce3620af0d1b62b267184ef2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted track \n",
    "from IPython.display import Video\n",
    "Video(f\"{DATASET_PATH}/tracks_mp4/{extractor.dataset_domain}/{data['mp4_filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pipeline'></a>\n",
    "## Parse and extract tracks from a scene clip in a video using the TrackVerse automated pipeline\n",
    "For demo purpose, we only use one scene from the downloaded video and extract the tracks from that scene.\n",
    "\n",
    "To use the pipeline to create a full dataset, refer to the [pipeline instructions](https://github.com/MMPLab/TrackVerse/tree/main?tab=readme-ov-file#generate-customized-trackverse-dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained CLIP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yibingwei/.local/lib/python3.8/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from parse_tracks import ObjectTracksParser, parse_arguments\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "from bytetrack.byte_tracker import BYTETracker\n",
    "from utils import detic as detic_utils\n",
    "from utils import avio\n",
    "\n",
    "args = parse_arguments()\n",
    "args.base_dir = DATASET_PATH\n",
    "args.yid_index_fn = ''\n",
    "parser = ObjectTracksParser(args)\n",
    "\n",
    "detector = detic_utils.build_detic(\n",
    "            args.class_prompts,\n",
    "            args.frame_size,\n",
    "            args.nms,\n",
    "            args.conf,\n",
    "            gpu_id=0\n",
    "        )\n",
    "tracker = BYTETracker(\n",
    "    args.track_thresh,\n",
    "    args.track_iou_low_thresh,\n",
    "    args.match_thresh,\n",
    "    args.frame_rate,\n",
    "    args.track_buffer,\n",
    "    args.motion_weight,\n",
    "    args.mot20\n",
    ")\n",
    "\n",
    "youtube_id = data['yid']\n",
    "video_filepath = f\"{DATASET_PATH}/videos_mp4/{youtube_id[:2]}/{youtube_id}.mp4\"\n",
    "\n",
    "\n",
    "# Calculate the maximum batch size for the detector\n",
    "batch_size  = parser.get_max_batch_size(detector, avio.VideoDB(video_filepath).reader.frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo] Start parsing segment [157.991, 161.862].\n",
      "[0][1l4wfwq2TLo][62.2%] Parsing object tracks | InferenceSpeed= 1.72 sec video/sec | NumTracks=0.\n",
      "[0][1l4wfwq2TLo] Finished parsing segment. Found 0 tracks.\n"
     ]
    }
   ],
   "source": [
    "# You can get all segments of the video by reading prcoessed segm file and process them all.\n",
    "segm_filepath = f\"{DATASET_PATH}/videos_segm/{youtube_id[:2]}/{youtube_id}.txt\"\n",
    "segments = [ln.strip().split(',') for ln in open(segm_filepath, \"r\")]\n",
    "segments = [(float(start), float(end)) for start, end in segments]\n",
    "\n",
    "# For demo purpose, we only process the scene segment contraining the track extracted above\n",
    "for start, end in segments:\n",
    "    if end >= data['frame_ts'][-1] and start <= data['frame_ts'][0]:\n",
    "        seg_start = start\n",
    "        seg_end = end\n",
    "        break\n",
    "\n",
    "parser.parse_object_tracks(video_filepath, [seg_start, seg_end], detector, tracker, batch_size, job_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "meta_data = f\"trackverse/tracks_meta/TrackVerseLVIS/{youtube_id[:2]}/{youtube_id}-meta.jsonl.gzip\"\n",
    "for line in tqdm.tqdm(gzip.open(meta_data, 'rt')):\n",
    "    print(json.loads(line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
