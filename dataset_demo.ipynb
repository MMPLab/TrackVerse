{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noteook includes two demo\n",
    "1. [Download](#download) a track from the JSONL file\n",
    "2. [Parse and extract](#pipeline) tracks in a video using the TrackVerse automated pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.288177Z",
     "start_time": "2024-06-18T20:25:40.285224Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json, gzip\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='download'></a>\n",
    "## Download tracks from the JSONL file\n",
    "### (1) Read the JSONL file\n",
    "For demo purpose, we only read one track from the 184K-CB300 subset to show how to read the jonsl file and download correspoonding tracks.\n",
    "\n",
    "To just download the dataset, refer to the [download instructions](https://github.com/MMPLab/TrackVerse?tab=readme-ov-file#download-trackverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.315756Z",
     "start_time": "2024-06-18T20:25:40.315459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yid\n",
      "fn\n",
      "video_size\n",
      "top10_lbl\n",
      "top10_desc\n",
      "top10_logit_mu\n",
      "top10_logit_std\n",
      "top10_wlogit_mu\n",
      "top10_wlogit_std\n",
      "track_ts\n",
      "track_bbox\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = './TrackVerseDB'\n",
    "subset_gzip = f\"{DATASET_PATH}/tracks_subsets/TrackVerseLVIS-CB300-184K-T0.jsonl.gzip\"\n",
    "for line in gzip.open(subset_gzip, 'rt'):\n",
    "    data = json.loads(line)\n",
    "    print('\\n'.join(data.keys()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format\n",
    "\n",
    "- `yid` - YouTube ID for the video from which this track was extracted\n",
    "- `fn` - Filename of the track produced by running the track extraction pipeline.\n",
    "- `video_size` - [height, width] of the video from which this track was extracted.\n",
    "- `top10_lbl` - Class IDs of the top-10 predicted classes for the track, based on weighted class logit score.\n",
    "- `top10_desc` - Names of the top-10 predicted classes.\n",
    "- `top10_logit_mu` - Average (over time) of the classification logits for the `top10_lbl` classes.\n",
    "- `top10_logit_std` - Standard deviation (over time) of the classification logits for the `top10_lbl` classes.\n",
    "- `top10_wlogit_mu` - Average (over time) of the classification logits weighted by DETIC's objectness score for the `top10_lbl` classes.\n",
    "- `top10_wlogit_std` - Standard deviation (over time) of the classification logits weighted by DETIC's objectness score for the `top10_lbl` classes.\n",
    "- `track_ts` - Timestamps (seconds) in the original video for each frame in the track\n",
    "- `track_bbox` - Bounding box coordinates [top_left_x, top_left_y, bottom_right_x, bottom_right_y] of the object for each frame in the track."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "youtube_id = data['yid']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.315995Z",
     "start_time": "2024-06-18T20:25:40.315562Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Download the original video from Youtube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.345644Z",
     "start_time": "2024-06-18T20:25:40.315605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(<STATUS.DONE: 2>, './temporary-folder//videos_mp4/1l/1l4wfwq2TLo.mp4')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.youtube import YoutubeDL\n",
    "TMP_PATH = './temporary-folder'\n",
    "os.makedirs(f\"{TMP_PATH}/videos_mp4\", exist_ok=True)\n",
    "downloader = YoutubeDL(f\"{TMP_PATH}/videos_mp4\")\n",
    "downloader.download_video(youtube_id=data['yid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Extract the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.384332Z",
     "start_time": "2024-06-18T20:25:40.339956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo] Start track extraction\n",
      "[0][1l4wfwq2TLo] Track extraction done.\n"
     ]
    }
   ],
   "source": [
    "from extract_tracks import ObjectTrackExtractor, Track\n",
    "import numpy as np\n",
    "extractor = ObjectTrackExtractor(base_dir=TMP_PATH, dataset_domain='LVIS')\n",
    "\n",
    "track = Track(data['yid'],\n",
    "              fn=data['fn'],\n",
    "              ts=np.array(data['track_ts']).astype(float),\n",
    "              boxes=np.array(data['track_bbox']).astype(float),\n",
    "              meta=data)\n",
    "extractor.extract_tracks_from_video(vid=data['yid'], tracks=[track], job_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:25:40.384841Z",
     "start_time": "2024-06-18T20:25:40.384162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"./temporary-folder//tracks_mp4/LVIS/1l/1l4wfwq2TLo-coat-0b20cf63ce3620af0d1b62b267184ef2.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted track \n",
    "Video(f\"{TMP_PATH}/tracks_mp4/{extractor.dataset_domain}/{data['fn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pipeline'></a>\n",
    "## Parse and extract tracks from a scene clip in a video using the TrackVerse automated pipeline\n",
    "For demo purpose, we only use one scene from the downloaded video and extract the tracks from that scene.\n",
    "\n",
    "To use the pipeline to create a full dataset, refer to the [pipeline instructions](https://github.com/MMPLab/TrackVerse/tree/main?tab=readme-ov-file#generate-customized-trackverse-dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:26:01.598936Z",
     "start_time": "2024-06-18T20:25:40.384282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained CLIP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmorgado/miniconda3/envs/trackverse/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001B[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.mask_head.deconv.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.mask_head.predictor.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo] Start parsing segment [100, 120].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmorgado/miniconda3/envs/trackverse/lib/python3.8/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1l4wfwq2TLo][39.2%] Parsing object tracks | InferenceSpeed= 1.46 sec video/sec | NumTracks=0.\n",
      "[0][1l4wfwq2TLo] Finished parsing segment. Found 12 tracks.\n"
     ]
    }
   ],
   "source": [
    "# You can get all segments of the video by reading processed segm file and process them all.\n",
    "from parse_tracks import ObjectTracksParser, DETIC_CFG, BYTETRACK_CFG\n",
    "video_filepath = f\"{TMP_PATH}/videos_mp4/{youtube_id[:2]}/{youtube_id}.mp4\"\n",
    "meta_data = f\"{TMP_PATH}/tracks_meta/LVIS/{youtube_id[:2]}/{youtube_id}-meta.jsonl.gzip\"\n",
    "if os.path.exists(meta_data):\n",
    "    os.remove(meta_data)\n",
    "parser = ObjectTracksParser(TMP_PATH, '', 'LVIS', DETIC_CFG(), BYTETRACK_CFG())\n",
    "parser.parse_object_tracks(video_filepath, [100, 120], batch_size=32, job_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:26:36.625507Z",
     "start_time": "2024-06-18T20:26:01.598826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'blazer' from 116.68323333333333 to 119.95316666666666\n",
      "'person' from 116.68323333333333 to 119.95316666666666\n",
      "'baseball cap' from 100.06663333333333 to 106.87343333333334\n",
      "'jersey' from 100.13336666666666 to 106.87343333333334\n",
      "'baseball cap' from 100.06663333333333 to 106.87343333333334\n",
      "'jersey' from 100.13336666666666 to 106.87343333333334\n",
      "'person' from 103.0029 to 108.3082\n",
      "'person' from 103.0029 to 108.3082\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'blazer' from 116.68323333333333 to 119.95316666666666\n",
      "'person' from 116.68323333333333 to 119.95316666666666\n",
      "'baseball cap' from 100.06663333333333 to 106.87343333333334\n",
      "'jersey' from 100.13336666666666 to 106.87343333333334\n",
      "'baseball cap' from 100.06663333333333 to 106.87343333333334\n",
      "'jersey' from 100.13336666666666 to 106.87343333333334\n",
      "'person' from 103.0029 to 108.3082\n",
      "'person' from 103.0029 to 108.3082\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "'person' from 106.94016666666667 to 116.6165\n",
      "[0][1l4wfwq2TLo] Start track extraction\n",
      "[0][1l4wfwq2TLo][Track 1/24][1l/1l4wfwq2TLo-blazer-1f1d07422325929b50afecc68f982f9a.mp4].\n",
      "[0][1l4wfwq2TLo][Track 2/24][1l/1l4wfwq2TLo-person-23c58804bec71e28c471fe7b6545ff84.mp4].\n",
      "[0][1l4wfwq2TLo][Track 3/24][1l/1l4wfwq2TLo-baseball-cap-ab4dd53532c8ca125be630bf2287699e.mp4].\n",
      "[0][1l4wfwq2TLo][Track 4/24][1l/1l4wfwq2TLo-jersey-25e28345ff4cf63700f50b4cf0c2502d.mp4].\n",
      "[0][1l4wfwq2TLo][Track 7/24][1l/1l4wfwq2TLo-person-732ebb678611e58d48e6af3785817baa.mp4].\n",
      "[0][1l4wfwq2TLo][Track 9/24][1l/1l4wfwq2TLo-person-0f7f9d9fe53bddbed2894ffc34035c13.mp4].\n",
      "[0][1l4wfwq2TLo][Track 10/24][1l/1l4wfwq2TLo-person-47a21bc7f8481f6141fae633890d3b9b.mp4].\n",
      "[0][1l4wfwq2TLo] Track extraction done.\n"
     ]
    }
   ],
   "source": [
    "extractor = ObjectTrackExtractor(base_dir=TMP_PATH, dataset_domain='LVIS')\n",
    "tracks = []\n",
    "for line in gzip.open(meta_data, 'rt'):\n",
    "    m = json.loads(line)\n",
    "    tracks.append(Track(m['yid'],\n",
    "                        fn=m['fn'],\n",
    "                        ts=np.array(m['track_ts']).astype(float),\n",
    "                        boxes=np.array(m['track_bbox']).astype(float),\n",
    "                        meta=data))\n",
    "    print(f\"'{m['top10_desc'][0]}' from {m['track_ts'][0]} to {m['track_ts'][-1]}\")\n",
    "extractor.extract_tracks_from_video(vid=m['yid'], tracks=tracks, job_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Video(f\"{TMP_PATH}/tracks_mp4/LVIS/{tracks[0].fn}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Video(f\"{TMP_PATH}/tracks_mp4/LVIS/{tracks[1].fn}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Video(f\"{TMP_PATH}/tracks_mp4/LVIS/{tracks[2].fn}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
